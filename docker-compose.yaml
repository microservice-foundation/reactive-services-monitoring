version: "3.9"
services:
  service-discovery-service:
    image: service-discovery-service:${TAG}
    hostname: service-discovery-service
    container_name: service-discovery-service
    restart: always
    ports:
      - ${SERVICE_REGISTERY_PORT}:${SERVICE_REGISTERY_PORT}
      - "8000:8001"
    environment:
      SERVER_PORT: ${SERVICE_REGISTERY_PORT}
      MICROSERVICE_NAME: service-discovery-service
    networks:
      - microservice-network
    labels:
      collect_logs_with_filebeat: ${COLLECT_LOGS_WITH_FILEBEAT}
      decode_log_event_to_json_object: ${DECODE_LOG_EVENT_TO_JSON_OBJECT}

  configuration-service:
    image: configuration-service:${TAG}
    hostname: configuration-service
    container_name: configuration-service
    restart: always
    ports:
      - "8001:8001" 
    depends_on: 
      - "service-discovery-service"
    environment:
      EUREKA_HOST: http://service-discovery-service:${SERVICE_REGISTERY_PORT}
      MICROSERVICE_NAME: configuration-service
    networks:
      - microservice-network
    labels:
      collect_logs_with_filebeat: ${COLLECT_LOGS_WITH_FILEBEAT}
      decode_log_event_to_json_object: ${DECODE_LOG_EVENT_TO_JSON_OBJECT}

  db:
    image: postgres:latest
    hostname: db
    container_name: db
    restart: always
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - microservice-network

  storage-service-reactive-r2dbc:
    image: storage-service-reactive-r2dbc:${TAG}
    hostname: storage-service-reactive-r2dbc
    container_name: storage-service-reactive-r2dbc
    restart: always
    ports:
      - "8006:8001" 
    depends_on:
      - "service-discovery-service"
      - "configuration-service"
      - "db"
    environment:
      MICROSERVICE_NAME: storage-service-reactive-r2dbc
      EUREKA_HOST: http://service-discovery-service:${SERVICE_REGISTERY_PORT}
      CONFIGURATION_SERVER_NAME: configuration-service
      DB_HOST: db
      DB_PORT: ${DB_PORT}
      DB_USERNAME: ${DB_USERNAME}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
    networks:
      - microservice-network
    labels:
      collect_logs_with_filebeat: ${COLLECT_LOGS_WITH_FILEBEAT}
      decode_log_event_to_json_object: ${DECODE_LOG_EVENT_TO_JSON_OBJECT}

  song-service-reactive-r2dbc:
    image: song-service-reactive-r2dbc:${TAG}
    hostname: song-service-reactive-r2dbc
    container_name: song-service-reactive-r2dbc
    restart: always
    ports:
      - "8002:8001" 
    depends_on:
      - "service-discovery-service"
      - "configuration-service"
      - "db"
    environment:
      MICROSERVICE_NAME: song-service-reactive-r2dbc
      EUREKA_HOST: http://service-discovery-service:${SERVICE_REGISTERY_PORT}
      CONFIGURATION_SERVER_NAME: configuration-service
      DB_HOST: db
      DB_PORT: ${DB_PORT}
      DB_USERNAME: ${DB_USERNAME}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
    networks:
      - microservice-network
    labels:
      collect_logs_with_filebeat: ${COLLECT_LOGS_WITH_FILEBEAT}
      decode_log_event_to_json_object: ${DECODE_LOG_EVENT_TO_JSON_OBJECT}

  zoo1:
    image: confluentinc/cp-zookeeper:7.3.0
    hostname: zoo1
    container_name: zoo1
    restart: always
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888
    networks:
      - microservice-network

  kafka1:
    image: confluentinc/cp-kafka:7.3.0
    hostname: kafka1
    container_name: kafka1
    restart: always
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zoo1
    networks:
      - microservice-network

  kafka2:
    image: confluentinc/cp-kafka:7.3.0
    hostname: kafka2
    container_name: kafka2
    restart: always
    ports:
      - "9093:9093"
      - "29093:29093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:19093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093,DOCKER://host.docker.internal:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zoo1
    networks:
      - microservice-network

  kafka3:
    image: confluentinc/cp-kafka:7.3.0
    hostname: kafka3
    container_name: kafka3
    restart: always
    ports:
      - "9094:9094"
      - "29094:29094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka3:19094,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094,DOCKER://host.docker.internal:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zoo1
    networks:
      - microservice-network

  resource-service-reactive-r2dbc:
    image: resource-service-reactive-r2dbc:${TAG}
    hostname: resource-service-reactive-r2dbc
    container_name: resource-service-reactive-r2dbc
    restart: always
    depends_on:
      - "service-discovery-service"
      - "configuration-service"
      - "db"
      - "zoo1"
      - "kafka1"
      - "kafka2"
      - "kafka3"
      - "storage-service-reactive-r2dbc"
    ports:
      - "8003:8001"
    environment:
      MICROSERVICE_NAME: resource-service-reactive-r2dbc
      EUREKA_HOST: http://service-discovery-service:${SERVICE_REGISTERY_PORT}
      CONFIGURATION_SERVER_NAME: configuration-service
      API_GATEWAY_SERVICE_NAME: api-gateway-service
      DB_HOST: db
      DB_PORT: ${DB_PORT}
      DB_USERNAME: ${DB_USERNAME}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      KAFKA_BOOTSTRAP_SERVERS_ENDPOINTS: kafka1:29092,kafka2:29093,kafka3:29094
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
    networks:
      - microservice-network
    labels:
      collect_logs_with_filebeat: ${COLLECT_LOGS_WITH_FILEBEAT}
      decode_log_event_to_json_object: ${DECODE_LOG_EVENT_TO_JSON_OBJECT}

  redis:
    image: redis:latest
    hostname: redis
    container_name: redis
    restart: always
    ports:
      - "6379:6379"
    networks:
      - microservice-network

  api-gateway-service:
    image: api-gateway-service:${TAG}
    hostname: api-gateway-service
    container_name: api-gateway-service
    depends_on: 
      - "redis"
      - "service-discovery-service"
      - "configuration-service"
      - "resource-service-reactive-r2dbc"
      - "song-service-reactive-r2dbc"
      - "storage-service-reactive-r2dbc"
    restart: always
    ports:
      - "8004:8001"
      - ${API_GATEWAY_PORT}:${API_GATEWAY_PORT}
    environment:
      MICROSERVICE_NAME: api-gateway-service
      EUREKA_HOST: http://service-discovery-service:${SERVICE_REGISTERY_PORT}
      CONFIGURATION_SERVER_NAME: configuration-service
      SERVER_PORT: ${API_GATEWAY_PORT}
      SONG_SERVICE_NAME: song-service-reactive-r2dbc
      RESOURCE_SERVICE_NAME: resource-service-reactive-r2dbc
      STORAGE_SERVICE_NAME: storage-service-reactive-r2dbc
      REDIS_HOST: redis
    networks:
      - microservice-network
    labels:
      collect_logs_with_filebeat: ${COLLECT_LOGS_WITH_FILEBEAT}
      decode_log_event_to_json_object: ${DECODE_LOG_EVENT_TO_JSON_OBJECT}

  resource-processor-service-reactive:
    image: resource-processor-service-reactive:${TAG}
    hostname: resource-processor-service-reactive
    container_name: resource-processor-service-reactive
    restart: always
    depends_on:
      - "service-discovery-service"
      - "configuration-service"
      - "api-gateway-service"
      - "zoo1"
      - "kafka1"
      - "kafka2"
      - "kafka3"
    ports:
      - "8005:8001"
    environment:
      MICROSERVICE_NAME: resource-processor-service-reactive
      EUREKA_HOST: http://service-discovery-service:${SERVICE_REGISTERY_PORT}
      API_GATEWAY_SERVICE_NAME: api-gateway-service
      KAFKA_BOOTSTRAP_SERVERS_ENDPOINTS: kafka1:29092,kafka2:29093,kafka3:29094
      CONFIGURATION_SERVER_NAME: configuration-service
    networks:
      - microservice-network
    labels:
      collect_logs_with_filebeat: ${COLLECT_LOGS_WITH_FILEBEAT}
      decode_log_event_to_json_object: ${DECODE_LOG_EVENT_TO_JSON_OBJECT}

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELK_STACK_VERSION}
    ports:
      - ${ES_PORT}:9200
    environment:
      - "discovery.type=single-node"
      - "xpack.security.enabled=false"
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
     memlock:
       soft: -1
       hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data:rw                     # Persistence data

  logstash:
    image: docker.elastic.co/logstash/logstash:${ELK_STACK_VERSION}
    ports:
      - "25826:25826"
      - "5044:5044"
    volumes:
      - ./.config/logstash/pipeline:/usr/share/logstash/pipeline:ro               # Pipeline configuration
    restart: always
    mem_limit: ${LS_MEM_LIMIT}
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:${ELK_STACK_VERSION}
    ports:
      - ${KIBANA_PORT}:5601
    restart: always
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:${ES_PORT}
    mem_limit: ${KB_MEM_LIMIT}
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:${ELK_STACK_VERSION}
    volumes:
      - ./.config/filebeat/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml:ro # Configuration file
      - /var/lib/docker/containers:/var/lib/docker/containers:ro                   # Docker logs
      - /var/run/docker.sock:/var/run/docker.sock:ro                               # Additional information about containers
      - filebead_data:/usr/share/filebeat/data:rw                                  # Persistence data
    user: root                                                                     # Allow access to log files and docker.sock
    restart: always
    depends_on:
      - logstash

volumes:
  postgres_data:
    driver: local
  filebead_data:
    driver: local
  elasticsearch_data:
    driver: local

networks:
  microservice-network:
    driver: bridge

